{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "689c8ecb-09ea-4cf4-b1bb-3a6613daf81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from scipy.stats import norm\n",
    "import time\n",
    "import os # For saving model\n",
    "\n",
    "# Use GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# --- Black-Scholes Parameters and Domain ---\n",
    "sigma = 0.2     # Volatility (fixed for this PINN)\n",
    "r = 0.05      # Risk-free rate (fixed for this PINN)\n",
    "K = 100.0     # Strike price\n",
    "T = 1.0       # Time to maturity\n",
    "S_min = 0.01  # Minimum stock price (avoid S=0 for stability)\n",
    "S_max = 200.0   # Maximum stock price\n",
    "\n",
    "# Model save path\n",
    "MODEL_SAVE_DIR = \"pinn_models\"\n",
    "MODEL_FILENAME = \"bs_pinn_stage2.pth\"\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, MODEL_FILENAME)\n",
    "LOSS_DATA_PATH = os.path.join(MODEL_SAVE_DIR, \"bs_pinn_stage2_losses.npz\")\n",
    "\n",
    "# Create directory if it doesn't exist\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "\n",
    "# --- Analytical Solution (for validation) ---\n",
    "def black_scholes_call_numpy(S, t, sigma, r, K=100, T=1):\n",
    "    \"\"\" Numpy version for validation plotting \"\"\"\n",
    "    tau = T - t\n",
    "    # Handle tau=0 explicitly to avoid division by zero / sqrt(0)\n",
    "    price = np.zeros_like(S)\n",
    "    # Need to handle scalar and array inputs carefully\n",
    "    is_scalar_S = np.isscalar(S)\n",
    "    is_scalar_t = np.isscalar(t)\n",
    "\n",
    "    if is_scalar_S and is_scalar_t:\n",
    "        S_arr, t_arr = np.array([S]), np.array([t])\n",
    "    elif is_scalar_S:\n",
    "        S_arr = np.full_like(t, S)\n",
    "        t_arr = t\n",
    "    elif is_scalar_t:\n",
    "        S_arr = S\n",
    "        t_arr = np.full_like(S, t)\n",
    "    else: \n",
    "        S_arr, t_arr = S, t\n",
    "\n",
    "    tau_arr = T - t_arr\n",
    "    price = np.zeros_like(S_arr)\n",
    "\n",
    "    idx_pos_tau = tau_arr > 1e-8\n",
    "    S_pos = S_arr[idx_pos_tau]\n",
    "    tau_pos = tau_arr[idx_pos_tau]\n",
    "\n",
    "    if S_pos.size > 0: # Ensure we don't compute on empty arrays\n",
    "        # Handle potential log(0) or division by zero if S_pos is near zero\n",
    "        S_pos = np.maximum(S_pos, 1e-10) # Clip S slightly above 0\n",
    "        d1 = (np.log(S_pos/K) + (r + 0.5 * sigma**2) * tau_pos) / (sigma * np.sqrt(tau_pos))\n",
    "        d2 = d1 - sigma * np.sqrt(tau_pos)\n",
    "        price[idx_pos_tau] = S_pos * norm.cdf(d1) - K * np.exp(-r * tau_pos) * norm.cdf(d2)\n",
    "\n",
    "    idx_zero_tau = ~idx_pos_tau\n",
    "    price[idx_zero_tau] = np.maximum(S_arr[idx_zero_tau] - K, 0.0)\n",
    "\n",
    "    # Return in the original shape/type if scalar was input\n",
    "    if is_scalar_S and is_scalar_t:\n",
    "        return price.item()\n",
    "    else:\n",
    "        return price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b55f8f8f-4aec-4e41-ba5b-53c19b78860a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PINN(nn.Module):\n",
    "    def __init__(self, hidden_dim=128): # Increased hidden_dim slightly\n",
    "        super(PINN, self).__init__()\n",
    "        # Input: (S, t), Output: u(S, t)\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2, hidden_dim),\n",
    "            nn.Tanh(), # Tanh is often preferred over ReLU in PINNs\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim),\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, hidden_dim), # Added one more layer\n",
    "            nn.Tanh(),\n",
    "            nn.Linear(hidden_dim, 1)\n",
    "        )\n",
    "        # Initialization (can sometimes help)\n",
    "        for m in self.net.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, S, t):\n",
    "        # Concatenate S and t to form the input tensor\n",
    "        X = torch.cat([S.reshape(-1, 1), t.reshape(-1, 1)], dim=1)\n",
    "        return self.net(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9335c9f2-023e-43bb-b677-ab66f726881c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pde_loss(model, S, t, sigma, r):\n",
    "    \"\"\" Calculates the PDE residual loss \"\"\"\n",
    "    S.requires_grad_(True)\n",
    "    t.requires_grad_(True)\n",
    "\n",
    "    u = model(S, t)\n",
    "\n",
    "    # First derivatives\n",
    "    u_t = torch.autograd.grad(u, t, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "    u_S = torch.autograd.grad(u, S, grad_outputs=torch.ones_like(u), create_graph=True)[0]\n",
    "\n",
    "    # Second derivative\n",
    "    u_SS = torch.autograd.grad(u_S, S, grad_outputs=torch.ones_like(u_S), create_graph=True)[0]\n",
    "\n",
    "    # PDE Residual ( L(u) = u_t + r*S*u_S + 0.5*sigma^2*S^2*u_SS - r*u )\n",
    "    # Ensure S used in residual calculation has requires_grad=True if needed later (already set)\n",
    "    residual = u_t + r * S * u_S + 0.5 * (sigma**2) * (S**2) * u_SS - r * u\n",
    "\n",
    "    # Mean Squared Error of the residual\n",
    "    loss_f = torch.mean(residual**2)\n",
    "    return loss_f\n",
    "\n",
    "def boundary_loss(model, n_bc, device):\n",
    "    \"\"\" Calculates the boundary condition losses \"\"\"\n",
    "    # BC 1: u(S_min, t) = 0\n",
    "    t_bc1 = torch.rand(n_bc, 1, device=device) * T  # Sample times t in [0, T]\n",
    "    S_bc1 = torch.full_like(t_bc1, S_min)        # Fixed S = S_min\n",
    "    u_bc1 = model(S_bc1, t_bc1)\n",
    "    loss_bc1 = torch.mean(u_bc1**2)\n",
    "\n",
    "    # BC 2: du/dS(S_max, t) = 1\n",
    "    t_bc2 = torch.rand(n_bc, 1, device=device) * T  # Sample times t in [0, T]\n",
    "    S_bc2 = torch.full_like(t_bc2, S_max)        # Fixed S = S_max\n",
    "    S_bc2.requires_grad_(True) # Need gradient w.r.t S\n",
    "\n",
    "    u_bc2 = model(S_bc2, t_bc2)\n",
    "    # Ensure u_S_bc2 is computed correctly\n",
    "    u_S_bc2 = torch.autograd.grad(u_bc2.sum(), S_bc2, create_graph=True)[0] # Use .sum() for scalar output grad\n",
    "    loss_bc2 = torch.mean((u_S_bc2 - 1.0)**2)\n",
    "\n",
    "    return loss_bc1 + loss_bc2\n",
    "\n",
    "def terminal_loss(model, n_ic, device):\n",
    "    \"\"\" Calculates the terminal condition loss (at t=T) \"\"\"\n",
    "    S_ic = torch.rand(n_ic, 1, device=device) * (S_max - S_min) + S_min # Sample S in [S_min, S_max]\n",
    "    t_ic = torch.full_like(S_ic, T)                         # Fixed t = T\n",
    "    u_ic = model(S_ic, t_ic)\n",
    "\n",
    "    # Target payoff: max(S - K, 0)\n",
    "    payoff = torch.maximum(S_ic - K, torch.zeros_like(S_ic))\n",
    "    loss_ic = torch.mean((u_ic - payoff)**2)\n",
    "    return loss_ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49d0c1ef-6512-4597-91d8-62713b6b3427",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate model and move to device\n",
    "pinn_model = PINN(hidden_dim=128).to(device) # Match hidden_dim from class definition\n",
    "\n",
    "# Optimizer and Scheduler\n",
    "# Trying AdamW and a potentially better scheduler\n",
    "optimizer = optim.AdamW(pinn_model.parameters(), lr=1e-3, weight_decay=1e-5)\n",
    "# Reduce LR significantly if loss plateaus for a while\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor=0.5, patience=1000, verbose=True)\n",
    "\n",
    "# Number of points for each loss component\n",
    "n_pde = 10000  # Collocation points for PDE residual\n",
    "n_bc = 1000   # Points for boundary conditions\n",
    "n_ic = 1000   # Points for terminal condition\n",
    "\n",
    "# Loss weights (Crucial for tuning!)\n",
    "w_pde = 1.0\n",
    "w_bc = 1.0   # Might need to increase weight for BCs if they learn slowly\n",
    "w_ic = 1.0   # Might need to increase weight for IC if payoff isn't matched well\n",
    "\n",
    "num_epochs = 10000 # Keep original number of epochs\n",
    "log_frequency = 500\n",
    "\n",
    "# Lists to store losses and corresponding epochs for plotting\n",
    "epochs_recorded = []\n",
    "losses = {'total': [], 'pde': [], 'bc': [], 'ic': []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6667c-a8ba-46ad-b762-b68d3a9f84d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Training...\n",
      "Epoch [1/10000], Loss: 1.5732e+03, PDE: 1.2649e-03, BC: 1.0259e+00, IC: 1.5722e+03, LR: 1.00e-03\n"
     ]
    }
   ],
   "source": [
    "print(\"Starting Training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    pinn_model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Sample points for PDE loss (collocation points in the interior)\n",
    "    # Ensure S_pde does not include boundaries where derivatives might be tricky\n",
    "    S_pde = torch.rand(n_pde, 1, device=device) * (S_max - S_min - 2*1e-5) + S_min + 1e-5\n",
    "    t_pde = torch.rand(n_pde, 1, device=device) * T # Sample t in [0, T) - avoid t=T exactly\n",
    "\n",
    "    # Calculate losses\n",
    "    loss_f = pde_loss(pinn_model, S_pde, t_pde, sigma, r)\n",
    "    loss_b = boundary_loss(pinn_model, n_bc, device)\n",
    "    loss_i = terminal_loss(pinn_model, n_ic, device)\n",
    "\n",
    "    # Total weighted loss\n",
    "    total_loss = w_pde * loss_f + w_bc * loss_b + w_ic * loss_i\n",
    "\n",
    "    # Backpropagation\n",
    "    total_loss.backward()\n",
    "    # Optional: Gradient Clipping (can help stability)\n",
    "    # torch.nn.utils.clip_grad_norm_(pinn_model.parameters(), max_norm=1.0)\n",
    "    optimizer.step()\n",
    "\n",
    "    # Scheduler step (based on total loss)\n",
    "    scheduler.step(total_loss)\n",
    "\n",
    "    # Logging\n",
    "    if (epoch + 1) % log_frequency == 0 or epoch == 0:\n",
    "        epochs_recorded.append(epoch + 1) # Record the actual epoch number\n",
    "        losses['total'].append(total_loss.item())\n",
    "        losses['pde'].append(loss_f.item())\n",
    "        losses['bc'].append(loss_b.item())\n",
    "        losses['ic'].append(loss_i.item())\n",
    "        print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
    "              f\"Loss: {total_loss.item():.4e}, \"\n",
    "              f\"PDE: {loss_f.item():.4e}, \"\n",
    "              f\"BC: {loss_b.item():.4e}, \"\n",
    "              f\"IC: {loss_i.item():.4e}, \"\n",
    "              f\"LR: {optimizer.param_groups[0]['lr']:.2e}\")\n",
    "\n",
    "end_time = time.time()\n",
    "training_time = end_time - start_time\n",
    "print(f\"\\nTraining finished in {training_time:.2f} seconds.\")\n",
    "\n",
    "# Convert recorded epochs to numpy array\n",
    "epochs_recorded_np = np.array(epochs_recorded)\n",
    "\n",
    "# Save losses and epochs\n",
    "np.savez(LOSS_DATA_PATH,\n",
    "         epochs=epochs_recorded_np,\n",
    "         total=np.array(losses['total']),\n",
    "         pde=np.array(losses['pde']),\n",
    "         bc=np.array(losses['bc']),\n",
    "         ic=np.array(losses['ic']),\n",
    "         training_time=training_time,\n",
    "         final_lr=optimizer.param_groups[0]['lr']) # Save final LR\n",
    "\n",
    "print(f\"Loss data saved to {LOSS_DATA_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462e26ac-1d31-4483-851c-dd450fa7017f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Load Model ---\n",
    "# Instantiate a new model instance (must have same architecture)\n",
    "pinn_model_loaded = PINN(hidden_dim=128).to(device) # Match architecture used for training\n",
    "\n",
    "try:\n",
    "    # Load the state dictionary\n",
    "    pinn_model_loaded.load_state_dict(torch.load(MODEL_SAVE_PATH, map_location=device))\n",
    "    pinn_model_loaded.eval() # Set model to evaluation mode\n",
    "    print(f\"Model loaded successfully from {MODEL_SAVE_PATH}\")\n",
    "\n",
    "    # --- Load Loss Data ---\n",
    "    loss_data = np.load(LOSS_DATA_PATH)\n",
    "    epochs_recorded_np = loss_data['epochs']\n",
    "    losses_loaded = {\n",
    "        'total': loss_data['total'],\n",
    "        'pde': loss_data['pde'],\n",
    "        'bc': loss_data['bc'],\n",
    "        'ic': loss_data['ic']\n",
    "    }\n",
    "    training_time_loaded = loss_data.get('training_time', 'N/A') # Use .get for backward compatibility\n",
    "    final_lr_loaded = loss_data.get('final_lr', 'N/A')\n",
    "    print(f\"Loss data loaded successfully from {LOSS_DATA_PATH}\")\n",
    "    print(f\"Training time from file: {training_time_loaded} seconds\")\n",
    "    print(f\"Final LR from file: {final_lr_loaded}\")\n",
    "\n",
    "    # Use the loaded model and data for plotting\n",
    "    pinn_model_to_plot = pinn_model_loaded\n",
    "    losses_to_plot = losses_loaded\n",
    "    epochs_to_plot = epochs_recorded_np\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: Model file '{MODEL_SAVE_PATH}' or loss file '{LOSS_DATA_PATH}' not found.\")\n",
    "    print(\"Please train the model first (run Cells 1-6) or ensure the files are in the correct directory.\")\n",
    "    # Optionally: fall back to using the model currently in memory if training was just run\n",
    "    # pinn_model_to_plot = pinn_model\n",
    "    # losses_to_plot = losses\n",
    "    # epochs_to_plot = epochs_recorded_np\n",
    "    # print(\"Falling back to using model/data currently in memory (if training was just run).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f12698-dba8-472d-b9db-6eb3f2bde303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have loaded or trained the model and loss data first\n",
    "# It expects 'epochs_to_plot' and 'losses_to_plot' to be defined\n",
    "\n",
    "if 'epochs_to_plot' in locals() and 'losses_to_plot' in locals():\n",
    "    plt.figure(figsize=(12, 7))\n",
    "\n",
    "    # Check if lengths match before plotting\n",
    "    if len(epochs_to_plot) == len(losses_to_plot['total']):\n",
    "        plt.plot(epochs_to_plot, losses_to_plot['total'], label='Total Loss', linewidth=2)\n",
    "        plt.plot(epochs_to_plot, losses_to_plot['pde'], label=f'PDE Loss (w={w_pde})', linestyle='--')\n",
    "        plt.plot(epochs_to_plot, losses_to_plot['bc'], label=f'BC Loss (w={w_bc})', linestyle='--')\n",
    "        plt.plot(epochs_to_plot, losses_to_plot['ic'], label=f'IC Loss (w={w_ic})', linestyle='--')\n",
    "\n",
    "        plt.xlabel('Epoch')\n",
    "        plt.ylabel('Loss Value (Log Scale)')\n",
    "        plt.title('PINN Training Losses for Black-Scholes')\n",
    "        plt.yscale('log')\n",
    "        plt.legend()\n",
    "        plt.grid(True, which=\"both\", ls=\"-\", alpha=0.5) # Add grid lines\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(f\"Error plotting losses: Mismatch in length between epochs ({len(epochs_to_plot)}) and losses ({len(losses_to_plot['total'])}).\")\n",
    "        print(\"Epochs recorded:\", epochs_to_plot)\n",
    "        # You might want to inspect the saved npz file here if loading failed somehow\n",
    "\n",
    "else:\n",
    "    print(\"Please run the training cell (Cell 5) or loading cell (Cell 7) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8450ba1f-9514-4f15-90a9-bbb731569bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have loaded or trained the model first\n",
    "# It expects 'pinn_model_to_plot' to be defined and loaded\n",
    "\n",
    "if 'pinn_model_to_plot' in locals():\n",
    "    pinn_model_to_plot.eval() # Ensure model is in eval mode\n",
    "\n",
    "    # 1. Solution Comparison Plot (Surface Plots)\n",
    "    n_plot = 100\n",
    "    S_plot = np.linspace(S_min, S_max, n_plot)\n",
    "    t_plot = np.linspace(0, T, n_plot)\n",
    "    S_grid, t_grid = np.meshgrid(S_plot, t_plot)\n",
    "\n",
    "    # Reshape for model input\n",
    "    S_flat = S_grid.flatten().reshape(-1, 1)\n",
    "    t_flat = t_grid.flatten().reshape(-1, 1)\n",
    "\n",
    "    # Convert to tensor for PINN prediction\n",
    "    S_tensor = torch.from_numpy(S_flat).float().to(device)\n",
    "    t_tensor = torch.from_numpy(t_flat).float().to(device)\n",
    "\n",
    "    # Get PINN predictions\n",
    "    start_pred_time = time.time()\n",
    "    with torch.no_grad():\n",
    "        u_pred_flat = pinn_model_to_plot(S_tensor, t_tensor).cpu().numpy()\n",
    "    end_pred_time = time.time()\n",
    "    print(f\"Prediction time for {n_plot*n_plot} points: {end_pred_time - start_pred_time:.4f} seconds\")\n",
    "\n",
    "    u_pred_grid = u_pred_flat.reshape(S_grid.shape)\n",
    "\n",
    "    # Get Analytical solution\n",
    "    u_analytical_grid = black_scholes_call_numpy(S_grid, t_grid, sigma, r, K, T)\n",
    "\n",
    "    # Calculate Absolute Error\n",
    "    abs_error_grid = np.abs(u_pred_grid - u_analytical_grid)\n",
    "    rel_error_grid = np.where(np.abs(u_analytical_grid) > 1e-6, abs_error_grid / np.abs(u_analytical_grid), 0) # Relative error (avoid division by zero)\n",
    "\n",
    "\n",
    "    # Plotting\n",
    "    fig = plt.figure(figsize=(18, 12)) # Increased figure size\n",
    "\n",
    "    # Plot 1: PINN Solution\n",
    "    ax1 = fig.add_subplot(221, projection='3d')\n",
    "    surf1 = ax1.plot_surface(S_grid, t_grid, u_pred_grid, cmap='viridis', edgecolor='none')\n",
    "    ax1.set_title('PINN Solution $u_{\\\\theta}(S, t)$')\n",
    "    ax1.set_xlabel('Stock Price S')\n",
    "    ax1.set_ylabel('Time t')\n",
    "    ax1.set_zlabel('Option Price u')\n",
    "    ax1.view_init(elev=30, azim=-120) # Adjust view angle\n",
    "    fig.colorbar(surf1, shrink=0.5, aspect=5, label='Price')\n",
    "\n",
    "    # Plot 2: Analytical Solution\n",
    "    ax2 = fig.add_subplot(222, projection='3d')\n",
    "    surf2 = ax2.plot_surface(S_grid, t_grid, u_analytical_grid, cmap='viridis', edgecolor='none')\n",
    "    ax2.set_title('Analytical Solution $u(S, t)$')\n",
    "    ax2.set_xlabel('Stock Price S')\n",
    "    ax2.set_ylabel('Time t')\n",
    "    ax2.set_zlabel('Option Price u')\n",
    "    ax2.view_init(elev=30, azim=-120)\n",
    "    fig.colorbar(surf2, shrink=0.5, aspect=5, label='Price')\n",
    "\n",
    "    # Plot 3: Absolute Error\n",
    "    ax3 = fig.add_subplot(223, projection='3d')\n",
    "    surf3 = ax3.plot_surface(S_grid, t_grid, abs_error_grid, cmap='plasma', edgecolor='none')\n",
    "    ax3.set_title('Absolute Error $|u_{\\\\theta} - u|$')\n",
    "    ax3.set_xlabel('Stock Price S')\n",
    "    ax3.set_ylabel('Time t')\n",
    "    ax3.set_zlabel('Error')\n",
    "    ax3.view_init(elev=30, azim=-120)\n",
    "    fig.colorbar(surf3, shrink=0.5, aspect=5, label='Abs Error')\n",
    "\n",
    "    # Plot 4: Relative Error\n",
    "    ax4 = fig.add_subplot(224, projection='3d')\n",
    "    # Use log scale for relative error sometimes helps visualize, clip max error\n",
    "    surf4 = ax4.plot_surface(S_grid, t_grid, np.minimum(rel_error_grid, 1.0), cmap='magma', edgecolor='none', vmax=1.0) # Cap relative error at 100% for colorbar\n",
    "    ax4.set_title('Relative Error $|u_{\\\\theta} - u| / |u|$ (capped at 1)')\n",
    "    ax4.set_xlabel('Stock Price S')\n",
    "    ax4.set_ylabel('Time t')\n",
    "    ax4.set_zlabel('Rel Error')\n",
    "    ax4.view_init(elev=30, azim=-120)\n",
    "    fig.colorbar(surf4, shrink=0.5, aspect=5, label='Rel Error')\n",
    "\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2. Solution Slice Plot (at specific time points)\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    times_to_plot = [0.0, T/4.0, T/2.0, T*0.75, T] # More time slices\n",
    "\n",
    "    for i, t_val in enumerate(times_to_plot):\n",
    "        S_slice_np = np.linspace(S_min, S_max, n_plot)\n",
    "        S_slice = torch.from_numpy(S_slice_np).float().reshape(-1, 1).to(device)\n",
    "        t_slice = torch.full_like(S_slice, t_val)\n",
    "        with torch.no_grad():\n",
    "            u_pred_slice = pinn_model_to_plot(S_slice, t_slice).cpu().numpy().flatten()\n",
    "\n",
    "        u_analytical_slice = black_scholes_call_numpy(S_slice_np, t_val, sigma, r, K, T)\n",
    "\n",
    "        color = plt.cm.cool(i / len(times_to_plot)) # Use a colormap for slices\n",
    "\n",
    "        # Plot analytical solution first (solid line)\n",
    "        plt.plot(S_slice_np, u_analytical_slice, color=color, linestyle='-', label=f'Analytical t={t_val:.2f}')\n",
    "        # Plot PINN prediction (dashed line or markers)\n",
    "        plt.plot(S_slice_np, u_pred_slice, color=color, linestyle='--', label=f'PINN t={t_val:.2f}')\n",
    "\n",
    "    plt.xlabel('Stock Price S')\n",
    "    plt.ylabel('Option Price u')\n",
    "    plt.title(f'PINN vs Analytical Solution at Different Times (sigma={sigma}, r={r})')\n",
    "    plt.legend(fontsize='small', ncol=2) # Adjust legend\n",
    "    plt.grid(True, alpha=0.5)\n",
    "    plt.ylim(bottom=-5) # Allow slightly negative for visual inspection if needed\n",
    "    plt.xlim(left=S_min)\n",
    "    plt.show()\n",
    "\n",
    "else:\n",
    "    print(\"Please run the training cell (Cell 5) or loading cell (Cell 7) first.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d8f61c-aaac-49c0-a40c-9f361a2791c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
